{"cells":[{"cell_type":"markdown","metadata":{},"source":["<font size=4>As I get closer to the grandmaster tier, I want to take this opportunity to thank this amazing community which has taught me so much about data science and life in general. I also want to thank everyone who made this journey so beautiful and memorable!</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import os\n","import gc\n","import re\n","import folium\n","import textstat\n","from scipy import stats\n","from colorama import Fore, Back, Style, init\n","\n","import math\n","import numpy as np\n","import scipy as sp\n","import pandas as pd\n","\n","import random\n","import networkx as nx\n","from pandas import Timestamp\n","\n","from PIL import Image\n","from IPython.display import SVG\n","# from keras.utils import model_to_dot\n","\n","import requests\n","from IPython.display import HTML\n","\n","import seaborn as sns\n","from tqdm import tqdm\n","import matplotlib.cm as cm\n","import matplotlib.pyplot as plt\n","\n","tqdm.pandas()\n","\n","import plotly.express as px\n","import plotly.graph_objects as go\n","import plotly.figure_factory as ff\n","from plotly.subplots import make_subplots\n","\n","import transformers\n","\n","from sklearn import metrics\n","from sklearn.utils import shuffle\n","from gensim.models import Word2Vec\n","from sklearn.cluster import KMeans\n","from sklearn.decomposition import PCA\n","from sklearn.feature_extraction.text import TfidfVectorizer,\\\n","                                            CountVectorizer,\\\n","                                            HashingVectorizer\n","\n","from nltk.stem.wordnet import WordNetLemmatizer \n","from nltk.tokenize import word_tokenize\n","from nltk.tokenize import TweetTokenizer  \n","\n","import nltk\n","from textblob import TextBlob\n","\n","from nltk.corpus import wordnet\n","from nltk.corpus import stopwords\n","from googletrans import Translator\n","from nltk import WordNetLemmatizer\n","from polyglot.detect import Detector\n","from nltk.stem import WordNetLemmatizer\n","from wordcloud import WordCloud, STOPWORDS\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","\n","stopword=set(STOPWORDS)\n","\n","lem = WordNetLemmatizer()\n","tokenizer=TweetTokenizer()\n","\n","np.random.seed(0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import icu\n","from polyglot.text import Text, Word"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["DATA_PATH = \"../input/jigsaw-multilingual-toxic-comment-classification/\"\n","os.listdir(DATA_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["TEST_PATH = DATA_PATH + \"test.csv\"\n","VAL_PATH = DATA_PATH + \"validation.csv\"\n","TRAIN_PATH = DATA_PATH + \"jigsaw-toxic-comment-train.csv\"\n","\n","val_data = pd.read_csv(VAL_PATH)\n","test_data = pd.read_csv(TEST_PATH)\n","train_data = pd.read_csv(TRAIN_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["def get_language(text):\n","    return Detector(\"\".join(x for x in text if x.isprintable()), quiet=True).languages[0].name\n","\n","train_data[\"lang\"] = train_data[\"comment_text\"].progress_apply(get_language)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["lang_list = sorted(list(set(train_data[\"lang\"])))\n","counts = [list(train_data[\"lang\"]).count(cont) for cont in lang_list]\n","df = pd.DataFrame(np.transpose([lang_list, counts]))\n","df.columns = [\"Language\", \"Count\"]\n","df[\"Count\"] = df[\"Count\"].apply(int)\n","\n","df_en = pd.DataFrame(np.transpose([[\"English\", \"Non-English\"], [max(counts), sum(counts) - max(counts)]]))\n","df_en.columns = [\"Language\", \"Count\"]\n","\n","fig = px.bar(df_en, x=\"Language\", y=\"Count\", title=\"Language of comments\", color=\"Language\", text=\"Count\")\n","fig.update_layout(template=\"plotly_white\")\n","fig.data[0].marker.line.color = 'rgb(0, 0, 0)'\n","fig.data[0].marker.line.width = 0.5\n","fig.data[1].marker.line.color = 'rgb(0, 0, 0)'\n","fig.data[1].marker.line.width = 0.5\n","fig.data[0].textfont.color = \"black\"\n","fig.data[0].textposition = \"outside\"\n","fig.data[1].textfont.color = \"black\"\n","fig.data[1].textposition = \"outside\"\n","fig"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["fig = px.bar(df.query(\"Language != 'English' and Language != 'un'\").query(\"Count >= 50\"),\n","             y=\"Language\", x=\"Count\", title=\"Language of non-English comments\", template=\"plotly_white\", color=\"Language\", text=\"Count\", orientation=\"h\")\n","fig.update_traces(marker=dict(line=dict(width=0.75,\n","                                        color='black')),  textposition=\"outside\")\n","fig.update_layout(showlegend=False)\n","fig"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["fig = go.Figure([go.Pie(labels=df.query(\"Language != 'English' and Language != 'un'\").query(\"Count >= 50\")[\"Language\"],\n","           values=df.query(\"Language != 'English' and Language != 'un'\").query(\"Count >= 50\")[\"Count\"])])\n","fig.update_layout(title_text=\"Pie chart of non-English languages\", template=\"plotly_white\")\n","fig.data[0].marker.colors = [px.colors.qualitative.Plotly[2:]]\n","fig.data[0].textfont.color = \"black\"\n","fig.data[0].textposition = \"outside\"\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["def new_len(x):\n","    if type(x) is str:\n","        return len(x.split())\n","    else:\n","        return 0\n","\n","train_data[\"comment_words\"] = train_data[\"comment_text\"].apply(new_len)\n","nums = train_data.query(\"comment_words != 0 and comment_words < 200\").sample(frac=0.1)[\"comment_words\"]\n","fig = ff.create_distplot(hist_data=[nums],\n","                         group_labels=[\"All comments\"],\n","                         colors=[\"coral\"])\n","\n","fig.update_layout(yaxis_title=\"Frequncy\",xaxis_title=\"Comment words\", template=\"simple_white\", showlegend=False)\n","\n","fig.update_layout(\n","    autosize=True,\n","    width=1000,\n","    height=400,)\n","picpath=\"pic/3_comment_words.png\"\n","fig.write_image(picpath)\n","print('![]({})'.format(picpath))\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["df = pd.DataFrame(np.transpose([lang_list, train_data.groupby(\"lang\").mean()[\"comment_words\"]]))\n","df.columns = [\"Language\", \"Average_comment_words\"]\n","df[\"Average_comment_words\"] = df[\"Average_comment_words\"].apply(float)\n","df = df.query(\"Average_comment_words < 500\")\n","fig = go.Figure(go.Bar(x=df[\"Language\"], y=df[\"Average_comment_words\"]))\n","\n","# fig.update_layout(xaxis_title=\"Language\", yaxis_title=\"Average comment words\", title_text=\"Average comment words vs. language\", template=\"plotly_white\")\n","fig.update_layout(xaxis_title=\"Language\", yaxis_title=\"Average comment words\", template=\"plotly_white\")\n","\n","fig.update_layout(\n","    autosize=True,\n","    width=1000,\n","    height=400,)\n","picpath=\"pic/3_comment_words_language.png\"\n","fig.write_image(picpath)\n","print('![]({})'.format(picpath))\n","\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["def polarity(x):\n","    if type(x) == str:\n","        return SIA.polarity_scores(x)\n","    else:\n","        return 1000\n","    \n","SIA = SentimentIntensityAnalyzer()\n","train_data[\"polarity\"] = train_data[\"comment_text\"].progress_apply(polarity)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["fig = go.Figure(go.Histogram(x=[pols[\"neg\"] for pols in train_data[\"polarity\"] if pols[\"neg\"] != 0], marker=dict(\n","            color='seagreen')\n","    ))\n","\n","# fig.update_layout(xaxis_title=\"Negativity sentiment\", title_text=\"Negativity sentiment\", template=\"simple_white\")\n","\n","fig.update_layout(yaxis_title=\"Count\",xaxis_title=\"Negativity sentiment\", template=\"simple_white\")\n","fig.update_layout(\n","    autosize=True,\n","    width=1000,\n","    height=400,)\n","picpath=\"pic/3_neg_sentence.png\"\n","fig.write_image(picpath)\n","print('![]({})'.format(picpath))\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["train_data[\"negativity\"] = train_data[\"polarity\"].apply(lambda x: x[\"neg\"])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["nums_1 = train_data.sample(frac=0.1).query(\"toxic == 1\")[\"negativity\"]\n","nums_2 = train_data.sample(frac=0.1).query(\"toxic == 0\")[\"negativity\"]\n","\n","fig = ff.create_distplot(hist_data=[nums_1, nums_2],\n","                         group_labels=[\"Toxic\", \"Non-toxic\"],\n","                         colors=[\"darkorange\", \"dodgerblue\"], show_hist=False)\n","\n","# fig.update_layout(title_text=\"Negativity vs. Toxicity\", xaxis_title=\"Negativity\", template=\"simple_white\")\n","fig.update_layout(yaxis_title=\"Count\",xaxis_title=\"Negativity\", template=\"simple_white\")\n","fig.update_layout(\n","    autosize=True,\n","    width=1000,\n","    height=400,)\n","picpath=\"pic/3_neg_toxic.png\"\n","fig.write_image(picpath)\n","print('![]({})'.format(picpath))\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["train_data[\"positivity\"] = train_data[\"polarity\"].apply(lambda x: x[\"pos\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["nums_1 = train_data.sample(frac=0.1).query(\"toxic == 1\")[\"positivity\"]\n","nums_2 = train_data.sample(frac=0.1).query(\"toxic == 0\")[\"positivity\"]\n","\n","fig = ff.create_distplot(hist_data=[nums_1, nums_2],\n","                         group_labels=[\"Toxic\", \"Non-toxic\"],\n","                         colors=[\"darkorange\", \"dodgerblue\"], show_hist=False)\n","\n","fig.update_layout(yaxis_title=\"Count\",xaxis_title=\"Positivity\", template=\"simple_white\")\n","fig.update_layout(\n","    autosize=True,\n","    width=1000,\n","    height=400,)\n","picpath=\"pic/3_pos_toxic.png\"\n","fig.write_image(picpath)\n","print('![]({})'.format(picpath))\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["fig = go.Figure(go.Histogram(x=[pols[\"neu\"] for pols in train_data[\"polarity\"] if pols[\"neu\"] != 1], marker=dict(\n","            color='dodgerblue')\n","    ))\n","\n","fig.update_layout(yaxis_title=\"Count\",xaxis_title=\"Neutrality sentiment\", template=\"simple_white\")\n","fig.update_layout(\n","    autosize=True,\n","    width=1000,\n","    height=400,)\n","picpath=\"pic/3_neu_sentence.png\"\n","fig.write_image(picpath)\n","print('![]({})'.format(picpath))\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["train_data[\"neutrality\"] = train_data[\"polarity\"].apply(lambda x: x[\"neu\"])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["nums_1 = train_data.sample(frac=0.1).query(\"toxic == 1\")[\"neutrality\"]\n","nums_2 = train_data.sample(frac=0.1).query(\"toxic == 0\")[\"neutrality\"]\n","\n","fig = ff.create_distplot(hist_data=[nums_1, nums_2],\n","                         group_labels=[\"Toxic\", \"Non-toxic\"],\n","                         colors=[\"darkorange\", \"dodgerblue\"], show_hist=False)\n","\n","fig.update_layout(yaxis_title=\"Count\",xaxis_title=\"Neutrality\", template=\"simple_white\")\n","fig.update_layout(\n","    autosize=True,\n","    width=1000,\n","    height=400,)\n","picpath=\"pic/3_neu_toxic.png\"\n","fig.write_image(picpath)\n","print('![]({})'.format(picpath))\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["fig = go.Figure(go.Histogram(x=[pols[\"compound\"] for pols in train_data[\"polarity\"] if pols[\"compound\"] != 0], marker=dict(\n","            color='orchid')\n","    ))\n","\n","fig.update_layout(yaxis_title=\"Count\",xaxis_title=\"Compound sentiment\", template=\"simple_white\")\n","fig.update_layout(\n","    autosize=True,\n","    width=1000,\n","    height=400,)\n","picpath=\"pic/3_all_sentence.png\"\n","fig.write_image(picpath)\n","print('![]({})'.format(picpath))\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["train_data[\"compound\"] = train_data[\"polarity\"].apply(lambda x: x[\"compound\"])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["nums_1 = train_data.sample(frac=0.1).query(\"toxic == 1\")[\"compound\"]\n","nums_2 = train_data.sample(frac=0.1).query(\"toxic == 0\")[\"compound\"]\n","\n","fig = ff.create_distplot(hist_data=[nums_1, nums_2],\n","                         group_labels=[\"Toxic\", \"Non-toxic\"],\n","                         colors=[\"darkorange\", \"dodgerblue\"], show_hist=False)\n","\n","fig.update_layout(xaxis_title=\"Compound\",yaxis_title=\"Count\",template=\"simple_white\")\n","fig.update_layout(\n","    autosize=True,\n","    width=1000,\n","    height=400,)\n","picpath=\"pic/3_all_toxic.png\"\n","fig.write_image(picpath)\n","print('![]({})'.format(picpath))\n","fig.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":4}
